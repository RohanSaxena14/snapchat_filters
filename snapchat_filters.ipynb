{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snapchat_filters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvthxAcX9GxUVwSUpRWP7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RohanSaxena14/snapchat_filters/blob/master/snapchat_filters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzNZZHdqRJSJ",
        "colab_type": "text"
      },
      "source": [
        "# **Collecting all the relevant data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sgxA3Kyu6GD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget \"https://github.com/italojs/facial-landmarks-recognition/raw/master/shape_predictor_68_face_landmarks.dat\"\n",
        "!wget \"http://arunponnusamy.com/files/mmod_human_face_detector.dat\"\n",
        "!wget \"https://github.com/RohanSaxena14/snapchat_filters/raw/master/data/mr bean.mp4\"\n",
        "!wget \"https://github.com/RohanSaxena14/snapchat_filters/raw/master/data/Eye.png\"\n",
        "!wget \"https://github.com/RohanSaxena14/snapchat_filters/raw/master/data/tongue.png\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7GEhXdFRl6R",
        "colab_type": "text"
      },
      "source": [
        "# **Importing all relevant packages and initializing the dlib's face detector and face_landmark detector**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QPW9860vpcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"/content/mmod_human_face_detector.dat\") # The cnn face detector in dlib\n",
        "face_detector = dlib.get_frontal_face_detector() # The other face detector in dlib\n",
        "predictor = dlib.shape_predictor(\"/content/shape_predictor_68_face_landmarks.dat\") #The facial_keypoint detector in dlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJGXI4zaSSqd",
        "colab_type": "text"
      },
      "source": [
        "# **This functions inserts the clipart in our frame and takes care of its shape as well**\n",
        "# i have used the concept of fore_ground and back_ground here to combine our clipart with the frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS1S0ppJO1XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function takes in the frame, the size and points and out clipart and combine the image\n",
        "\n",
        "def insert_clipart(frame, points, size, clipart):\n",
        "  clipart = cv2.resize(clipart, (2*size, 2*size)) # Resizing the clipart into appropriate size\n",
        "  orig_mask = clipart[:,:,3] # The 4th layer in our clipart image is the transparency layer, we are using it as a mask to cut-out the exact shape ou the eye\n",
        "  inv_mask = 255 - orig_mask # The inverse mask will be used to mask out the parts from out frame\n",
        "  clipart = clipart[:, :, 0:3] # After getting the mask, we are converting the image back to a normal BGR image\n",
        "\n",
        "  cut = frame[points[1]: points[1] + 2*size, points[0]: points[0] + 2*size, :] # The relevant part from the image is cut for manipulation\n",
        "  \n",
        "  # Using mask approprite cuts are made\n",
        "\n",
        "  cut = cv2.bitwise_and(cut, cut, mask = inv_mask) \n",
        "  clipart = cv2.bitwise_and(clipart, clipart, mask = orig_mask)\n",
        "\n",
        "  cut = cv2.add(cut, clipart) # Adding the two cuts\n",
        "\n",
        "  frame[points[1]:points[1]+ 2*size, points[0]:points[0]+ 2*size, :] = cut # Returning the cut to the main frame after processing\n",
        "\n",
        "  return frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwvnMOwmToQR",
        "colab_type": "text"
      },
      "source": [
        "# **Mainly we are concerned with the points around eyes here, the main code is here, i have added appropriate comments for better understanding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqUPLbawqVDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cap = cv2.VideoCapture(\"mr bean.mp4\")  # The video we are doing editing on\n",
        "\n",
        "ret, image = cap.read()\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "out = cv2.VideoWriter('output.avi',fourcc, 20.0, (image.shape[1], image.shape[0])) # For storing processed frames\n",
        "\n",
        "eye = cv2.imread(\"/content/Eye.png\", -1) # Our eye image, note that we are loading the image as-it-is as it has transparency properties\n",
        "\n",
        "while cap.isOpened():  # Looping on frames on our video\n",
        "    ret, image = cap.read()\n",
        "\n",
        "    if ret == False:\n",
        "      break\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = cnn_face_detector(image, 1) # Detecting faces using dlib\n",
        "\n",
        "    for face in faces: # Looping on all detected faces\n",
        "      \n",
        "      # This code draws rectangle around faces\n",
        "\n",
        "      '''\n",
        "\n",
        "      x = face.rect.left()\n",
        "      y = face.rect.top()\n",
        "      w = face.rect.right() - x\n",
        "      h = face.rect.bottom() - y\n",
        "      \n",
        "      cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
        "      '''\n",
        "      \n",
        "\n",
        "      points = predictor(gray, face.rect) # Predicting all 68 points on the detected face\n",
        "\n",
        "      \n",
        "      for i in range(0, 68): # Looping around all he points and plotting them on our frame\n",
        "        point = (points.part(i).x, points.part(i).y)\n",
        "\n",
        "        cv2.circle(image, point, 1, (0, 255, 0), -1)\n",
        "      \n",
        "      # Taking all the relevent points\n",
        "\n",
        "      p_38 = np.array([int((points.part(37).x + points.part(38).x)/2), int((points.part(37).y + points.part(38).y)/2)])\n",
        "      p_41 = np.array([int((points.part(40).x + points.part(41).x)/2), int((points.part(40).y + points.part(41).y)/2)])\n",
        "\n",
        "      p_44 = np.array([int((points.part(43).x + points.part(44).x)/2), int((points.part(43).y + points.part(44).y)/2)])\n",
        "      p_47 = np.array([int((points.part(46).x + points.part(47).x)/2), int((points.part(46).y + points.part(47).y)/2)])\n",
        "\n",
        "      p_43 = np.array([points.part(42).x, points.part(42).y])\n",
        "      p_46 = np.array([points.part(45).x, points.part(45).y])\n",
        "\n",
        "      p_37 = np.array([points.part(36).x, points.part(36).y])\n",
        "      p_40 = np.array([points.part(39).x, points.part(39).y])\n",
        "\n",
        "      # Calculating distances is very beneficial in deciding both the position and size of our clipart  \n",
        "\n",
        "      eye_vertical_left = np.linalg.norm(p_38 - p_41).astype(int)\n",
        "      eye_vertical_right = np.linalg.norm(p_44 - p_47).astype(int)\n",
        "\n",
        "      eye_horizontal_right = np.linalg.norm(p_43 - p_46).astype(int)\n",
        "      eye_horizontal_left = np.linalg.norm(p_37 - p_40).astype(int)\n",
        "\n",
        "      #if eye_vertical_left/eye_horizontal_right >= 0.4 and eye_vertical_right/eye_horizontal_right >= 0.4: #if you want to add eyes only when your eyes are wide open\n",
        "      if True: #when you want to add eyes on all frames\n",
        "        corner_x = p_37[0] - int(eye_horizontal_left / 2)\n",
        "        corner_y = p_37[1] - eye_horizontal_left\n",
        "\n",
        "        points_left_eye = (corner_x, corner_y)\n",
        "\n",
        "        image = insert_clipart(image, points_left_eye, eye_horizontal_left, eye)\n",
        "\n",
        "        corner_x = p_43[0] - int(eye_horizontal_right / 2)\n",
        "        corner_y = p_43[1] - eye_horizontal_right\n",
        "\n",
        "        points_right_eye = (corner_x, corner_y)\n",
        "\n",
        "        # Calling the function we made earlier\n",
        "\n",
        "        image = insert_clipart(image, points_right_eye, eye_horizontal_right, eye)  \n",
        "    \n",
        "\n",
        "    out.write(image) # Writing the processed frames\n",
        "\n",
        "cap.release()\n",
        "out.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4x0IevjcDk9",
        "colab_type": "text"
      },
      "source": [
        "# **HAPPY LEARNING !!!!! ðŸ˜„**"
      ]
    }
  ]
}